{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Car = pd.read_csv('car.data', sep=\",\")\n",
    "Car.columns = [\n",
    "    \"buying_price\",           # vhigh\n",
    "    \"maintenance_price\",      # vhigh.1\n",
    "    \"doors\",                  # 2\n",
    "    \"persons\",                # 2.1\n",
    "    \"luggage_boot_size\",      # small\n",
    "    \"safety\",                 # low\n",
    "    \"car_acceptability\"       # unacc\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_16860\\1832253008.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  Car['car_acceptability'] = Car['car_acceptability'].replace({\n"
     ]
    }
   ],
   "source": [
    "Car['car_acceptability'] = Car['car_acceptability'].replace({\n",
    "    'unacc': 0,  # Unacceptable\n",
    "    'acc': 1,    # Acceptable\n",
    "    'good': 1,   # Acceptable\n",
    "    'vgood': 1  # Acceptable\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_acceptability\n",
       "0    1209\n",
       "1     518\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Car['car_acceptability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Data (first 5 rows):\n",
      "   buying_price  maintenance_price  doors  persons  luggage_boot_size  safety  \\\n",
      "0             3                  3      0        0                  2       2   \n",
      "1             3                  3      0        0                  2       0   \n",
      "2             3                  3      0        0                  1       1   \n",
      "3             3                  3      0        0                  1       2   \n",
      "4             3                  3      0        0                  1       0   \n",
      "\n",
      "   car_acceptability  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n"
     ]
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "for column in Car.columns:\n",
    "    if Car[column].dtype == 'object':  # Check if column is categorical\n",
    "        le = LabelEncoder()\n",
    "        Car[column] = le.fit_transform(Car[column])\n",
    "        label_encoders[column] = le  # Store the encoder for future reference\n",
    "\n",
    "# 3. Verify encoding\n",
    "print(\"\\nEncoded Data (first 5 rows):\")\n",
    "print(Car.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_price</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>luggage_boot_size</th>\n",
       "      <th>safety</th>\n",
       "      <th>car_acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1727 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying_price  maintenance_price  doors  persons  luggage_boot_size  \\\n",
       "0                3                  3      0        0                  2   \n",
       "1                3                  3      0        0                  2   \n",
       "2                3                  3      0        0                  1   \n",
       "3                3                  3      0        0                  1   \n",
       "4                3                  3      0        0                  1   \n",
       "...            ...                ...    ...      ...                ...   \n",
       "1722             1                  1      3        2                  1   \n",
       "1723             1                  1      3        2                  1   \n",
       "1724             1                  1      3        2                  0   \n",
       "1725             1                  1      3        2                  0   \n",
       "1726             1                  1      3        2                  0   \n",
       "\n",
       "      safety  car_acceptability  \n",
       "0          2                  0  \n",
       "1          0                  0  \n",
       "2          1                  0  \n",
       "3          2                  0  \n",
       "4          0                  0  \n",
       "...      ...                ...  \n",
       "1722       2                  1  \n",
       "1723       0                  1  \n",
       "1724       1                  0  \n",
       "1725       2                  1  \n",
       "1726       0                  1  \n",
       "\n",
       "[1727 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'n_estimators': 400, 'max_features': None, 'criterion': 'entropy'}\n",
      "Test Set Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       237\n",
      "           1       1.00      1.00      1.00       109\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      1.00      1.00       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Replace with your dataset\n",
    "y = Car[\"car_acceptability\"]               # Replace with your dataset\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of combinations to try\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test set using the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.13%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       239\n",
      "           1       1.00      0.97      0.99       107\n",
      "\n",
      "    accuracy                           0.99       346\n",
      "   macro avg       0.99      0.99      0.99       346\n",
      "weighted avg       0.99      0.99      0.99       346\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.95%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       239\n",
      "           1       0.93      0.93      0.93       107\n",
      "\n",
      "    accuracy                           0.96       346\n",
      "   macro avg       0.95      0.95      0.95       346\n",
      "weighted avg       0.96      0.96      0.96       346\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.84%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       239\n",
      "           1       0.97      0.99      0.98       107\n",
      "\n",
      "    accuracy                           0.99       346\n",
      "   macro avg       0.98      0.99      0.99       346\n",
      "weighted avg       0.99      0.99      0.99       346\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.991329             1.000000          0.971963            0.985782\n",
      "1      2  0.959538             0.934579          0.934579            0.934579\n",
      "2      3  0.988439             0.972477          0.990654            0.981481\n",
      "Average Accuracy across the 3 trials: 97.98%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=400, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.61%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       595\n",
      "           1       0.97      0.98      0.98       269\n",
      "\n",
      "    accuracy                           0.99       864\n",
      "   macro avg       0.98      0.98      0.98       864\n",
      "weighted avg       0.99      0.99      0.99       864\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.61%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       605\n",
      "           1       0.96      0.99      0.98       259\n",
      "\n",
      "    accuracy                           0.99       864\n",
      "   macro avg       0.98      0.99      0.98       864\n",
      "weighted avg       0.99      0.99      0.99       864\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.69%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       594\n",
      "           1       0.95      0.98      0.96       270\n",
      "\n",
      "    accuracy                           0.98       864\n",
      "   macro avg       0.97      0.98      0.97       864\n",
      "weighted avg       0.98      0.98      0.98       864\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.986111             0.974170          0.981413            0.977778\n",
      "1      2  0.986111             0.962547          0.992278            0.977186\n",
      "2      3  0.976852             0.949640          0.977778            0.963504\n",
      "Average Accuracy across the 3 trials: 98.30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=400, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.15%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       956\n",
      "           1       0.93      0.91      0.92       426\n",
      "\n",
      "    accuracy                           0.95      1382\n",
      "   macro avg       0.94      0.94      0.94      1382\n",
      "weighted avg       0.95      0.95      0.95      1382\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.22%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       975\n",
      "           1       0.91      0.93      0.92       407\n",
      "\n",
      "    accuracy                           0.95      1382\n",
      "   macro avg       0.94      0.94      0.94      1382\n",
      "weighted avg       0.95      0.95      0.95      1382\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.07%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       963\n",
      "           1       0.90      0.90      0.90       419\n",
      "\n",
      "    accuracy                           0.94      1382\n",
      "   macro avg       0.93      0.93      0.93      1382\n",
      "weighted avg       0.94      0.94      0.94      1382\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.951520             0.928401          0.913146            0.920710\n",
      "1      2  0.952243             0.912833          0.926290            0.919512\n",
      "2      3  0.940666             0.902148          0.902148            0.902148\n",
      "Average Accuracy across the 3 trials: 94.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=400, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'C': 1000}\n",
      "Accuracy: 99.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       237\n",
      "           1       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      1.00      1.00       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  # Regularization parameter\n",
    "}\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 65.61%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71       239\n",
      "           1       0.47      0.78      0.58       107\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.66      0.69      0.65       346\n",
      "weighted avg       0.74      0.66      0.67       346\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 67.63%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73       239\n",
      "           1       0.49      0.77      0.59       107\n",
      "\n",
      "    accuracy                           0.68       346\n",
      "   macro avg       0.67      0.70      0.66       346\n",
      "weighted avg       0.74      0.68      0.69       346\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 76.30%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81       239\n",
      "           1       0.59      0.79      0.67       107\n",
      "\n",
      "    accuracy                           0.76       346\n",
      "   macro avg       0.74      0.77      0.74       346\n",
      "weighted avg       0.80      0.76      0.77       346\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.656069             0.466292          0.775701            0.582456\n",
      "1      2  0.676301             0.485207          0.766355            0.594203\n",
      "2      3  0.763006             0.586207          0.794393            0.674603\n",
      "Average Accuracy across the 3 trials: 69.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 68.17%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74       595\n",
      "           1       0.49      0.77      0.60       269\n",
      "\n",
      "    accuracy                           0.68       864\n",
      "   macro avg       0.68      0.71      0.67       864\n",
      "weighted avg       0.75      0.68      0.69       864\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 67.48%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74       605\n",
      "           1       0.47      0.74      0.58       259\n",
      "\n",
      "    accuracy                           0.67       864\n",
      "   macro avg       0.66      0.69      0.66       864\n",
      "weighted avg       0.74      0.67      0.69       864\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 71.53%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       594\n",
      "           1       0.53      0.78      0.63       270\n",
      "\n",
      "    accuracy                           0.72       864\n",
      "   macro avg       0.70      0.73      0.70       864\n",
      "weighted avg       0.77      0.72      0.73       864\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.681713             0.492857          0.769517            0.600871\n",
      "1      2  0.674769             0.472906          0.741313            0.577444\n",
      "2      3  0.715278             0.530151          0.781481            0.631737\n",
      "Average Accuracy across the 3 trials: 69.06%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 68.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74       956\n",
      "           1       0.49      0.78      0.60       426\n",
      "\n",
      "    accuracy                           0.69      1382\n",
      "   macro avg       0.68      0.71      0.67      1382\n",
      "weighted avg       0.75      0.69      0.70      1382\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 67.95%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       975\n",
      "           1       0.47      0.73      0.57       407\n",
      "\n",
      "    accuracy                           0.68      1382\n",
      "   macro avg       0.66      0.69      0.66      1382\n",
      "weighted avg       0.74      0.68      0.69      1382\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 68.45%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.74       963\n",
      "           1       0.49      0.77      0.60       419\n",
      "\n",
      "    accuracy                           0.68      1382\n",
      "   macro avg       0.68      0.71      0.67      1382\n",
      "weighted avg       0.75      0.68      0.70      1382\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.685239             0.493294          0.776995            0.603464\n",
      "1      2  0.679450             0.471429          0.729730            0.572806\n",
      "2      3  0.684515             0.487179          0.770883            0.597043\n",
      "Average Accuracy across the 3 trials: 68.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)  # Features\n",
    "y = Car[\"car_acceptability\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced',C = 1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Best Parameters and Results:\n",
      "Params      {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr...\n",
      "Accuracy                                                  1.0\n",
      "Name: 13, dtype: object\n",
      "\n",
      "Best Parameters:\n",
      "Hidden Layer 1 Size: 64\n",
      "Hidden Layer 2 Size: 32\n",
      "Learning Rate: 0.01\n",
      "\n",
      "Best Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lr\": [0.001, 0.01, 0.1],                # Learning rates to tune\n",
    "    \"hidden_size_1\": [32, 64, 128],          # Hidden layer 1 sizes to tune\n",
    "    \"hidden_size_2\": [16, 32, 64],           # Hidden layer 2 sizes to tune\n",
    "}\n",
    "\n",
    "# Convert the grid to a list of parameter combinations\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# To store results\n",
    "tuning_results = []\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for params in grid:\n",
    "    print(f\"\\nTesting Parameters: {params}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Define model with hyperparameters\n",
    "    class ANN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(ANN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, params[\"hidden_size_1\"])\n",
    "            self.fc2 = nn.Linear(params[\"hidden_size_1\"], params[\"hidden_size_2\"])\n",
    "            self.fc3 = nn.Linear(params[\"hidden_size_2\"], 2)  # 2 output classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 50  # Fixed number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "\n",
    "    # Append results\n",
    "    tuning_results.append({\n",
    "        \"Params\": params,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display the best parameters\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "best_result = results_df.loc[results_df[\"Accuracy\"].idxmax()]\n",
    "print(\"\\nBest Parameters and Results:\")\n",
    "print(best_result)\n",
    "\n",
    "best_params = best_result[\"Params\"]\n",
    "best_accuracy = best_result[\"Accuracy\"]\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"Hidden Layer 1 Size: {best_params['hidden_size_1']}\")\n",
    "print(f\"Hidden Layer 2 Size: {best_params['hidden_size_2']}\")\n",
    "print(f\"Learning Rate: {best_params['lr']}\")\n",
    "print(f\"\\nBest Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.4656\n",
      "Epoch [20/100], Loss: 0.3229\n",
      "Epoch [30/100], Loss: 0.1801\n",
      "Epoch [40/100], Loss: 0.0362\n",
      "Epoch [50/100], Loss: 0.0104\n",
      "Epoch [60/100], Loss: 0.0024\n",
      "Epoch [70/100], Loss: 0.0008\n",
      "Epoch [80/100], Loss: 0.0004\n",
      "Epoch [90/100], Loss: 0.0002\n",
      "Epoch [100/100], Loss: 0.0002\n",
      "Accuracy: 0.9942\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.4824\n",
      "Epoch [20/100], Loss: 0.4126\n",
      "Epoch [30/100], Loss: 0.2605\n",
      "Epoch [40/100], Loss: 0.1205\n",
      "Epoch [50/100], Loss: 0.0592\n",
      "Epoch [60/100], Loss: 0.0496\n",
      "Epoch [70/100], Loss: 0.0344\n",
      "Epoch [80/100], Loss: 0.0279\n",
      "Epoch [90/100], Loss: 0.0202\n",
      "Epoch [100/100], Loss: 0.0161\n",
      "Accuracy: 0.9769\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.5566\n",
      "Epoch [20/100], Loss: 0.2002\n",
      "Epoch [30/100], Loss: 0.0552\n",
      "Epoch [40/100], Loss: 0.0161\n",
      "Epoch [50/100], Loss: 0.0055\n",
      "Epoch [60/100], Loss: 0.0017\n",
      "Epoch [70/100], Loss: 0.0007\n",
      "Epoch [80/100], Loss: 0.0004\n",
      "Epoch [90/100], Loss: 0.0003\n",
      "Epoch [100/100], Loss: 0.0002\n",
      "Accuracy: 0.9942\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.994220\n",
      "1      2  0.976879\n",
      "2      3  0.994220\n",
      "Average Accuracy: 98.84%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.4603\n",
      "Epoch [20/100], Loss: 0.1849\n",
      "Epoch [30/100], Loss: 0.0884\n",
      "Epoch [40/100], Loss: 0.0313\n",
      "Epoch [50/100], Loss: 0.0149\n",
      "Epoch [60/100], Loss: 0.0094\n",
      "Epoch [70/100], Loss: 0.0068\n",
      "Epoch [80/100], Loss: 0.0054\n",
      "Epoch [90/100], Loss: 0.0045\n",
      "Epoch [100/100], Loss: 0.0038\n",
      "Accuracy: 0.9792\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.5024\n",
      "Epoch [20/100], Loss: 0.3845\n",
      "Epoch [30/100], Loss: 0.1858\n",
      "Epoch [40/100], Loss: 0.1237\n",
      "Epoch [50/100], Loss: 0.0706\n",
      "Epoch [60/100], Loss: 0.0438\n",
      "Epoch [70/100], Loss: 0.0335\n",
      "Epoch [80/100], Loss: 0.0228\n",
      "Epoch [90/100], Loss: 0.0209\n",
      "Epoch [100/100], Loss: 0.0201\n",
      "Accuracy: 0.9850\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.6171\n",
      "Epoch [20/100], Loss: 0.5510\n",
      "Epoch [30/100], Loss: 0.2765\n",
      "Epoch [40/100], Loss: 0.1469\n",
      "Epoch [50/100], Loss: 0.0641\n",
      "Epoch [60/100], Loss: 0.0347\n",
      "Epoch [70/100], Loss: 0.0270\n",
      "Epoch [80/100], Loss: 0.0253\n",
      "Epoch [90/100], Loss: 0.0246\n",
      "Epoch [100/100], Loss: 0.0243\n",
      "Accuracy: 0.9676\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.979167\n",
      "1      2  0.984954\n",
      "2      3  0.967593\n",
      "Average Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.4860\n",
      "Epoch [20/100], Loss: 0.3410\n",
      "Epoch [30/100], Loss: 0.2686\n",
      "Epoch [40/100], Loss: 0.1746\n",
      "Epoch [50/100], Loss: 0.0912\n",
      "Epoch [60/100], Loss: 0.0527\n",
      "Epoch [70/100], Loss: 0.0367\n",
      "Epoch [80/100], Loss: 0.0183\n",
      "Epoch [90/100], Loss: 0.0086\n",
      "Epoch [100/100], Loss: 0.0063\n",
      "Accuracy: 0.9486\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.4126\n",
      "Epoch [20/100], Loss: 0.1129\n",
      "Epoch [30/100], Loss: 0.0059\n",
      "Epoch [40/100], Loss: 0.0007\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [60/100], Loss: 0.0001\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Accuracy: 0.9551\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.3911\n",
      "Epoch [20/100], Loss: 0.0985\n",
      "Epoch [30/100], Loss: 0.0476\n",
      "Epoch [40/100], Loss: 0.0434\n",
      "Epoch [50/100], Loss: 0.0155\n",
      "Epoch [60/100], Loss: 0.0129\n",
      "Epoch [70/100], Loss: 0.0077\n",
      "Epoch [80/100], Loss: 0.0021\n",
      "Epoch [90/100], Loss: 0.0007\n",
      "Epoch [100/100], Loss: 0.0001\n",
      "Accuracy: 0.9284\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.948625\n",
      "1      2  0.955137\n",
      "2      3  0.928365\n",
      "Average Accuracy: 94.40%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam Tuning Using Normal Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_auc = 0\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "for n_estimators in [100, 200, 300]:\n",
    "    for max_depth in [3, 5, 7]:\n",
    "        for learning_rate in [0.01, 0.05, 0.1]:\n",
    "            xgb = XGBClassifier(\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            xgb.fit(X_train, y_train)\n",
    "            y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_depth': max_depth,\n",
    "                    'learning_rate': learning_rate\n",
    "                }\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 99.71%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       239\n",
      "           1       0.99      1.00      1.00       107\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      1.00      1.00       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 95.66%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       239\n",
      "           1       0.88      1.00      0.93       107\n",
      "\n",
      "    accuracy                           0.96       346\n",
      "   macro avg       0.94      0.97      0.95       346\n",
      "weighted avg       0.96      0.96      0.96       346\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 98.27%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       239\n",
      "           1       0.95      1.00      0.97       107\n",
      "\n",
      "    accuracy                           0.98       346\n",
      "   macro avg       0.97      0.99      0.98       346\n",
      "weighted avg       0.98      0.98      0.98       346\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.997110  1.000000             0.990741               1.0   \n",
      "1      2  0.956647  0.998319             0.877049               1.0   \n",
      "2      3  0.982659  0.999179             0.946903               1.0   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.995349  \n",
      "1            0.934498  \n",
      "2            0.972727  \n",
      "\n",
      "Average Accuracy across trials: 97.88%\n",
      "Average ROC-AUC across trials: 1.00\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)\n",
    "y = Car[\"car_acceptability\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 98.26%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       595\n",
      "           1       0.95      1.00      0.97       269\n",
      "\n",
      "    accuracy                           0.98       864\n",
      "   macro avg       0.97      0.99      0.98       864\n",
      "weighted avg       0.98      0.98      0.98       864\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 97.22%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       605\n",
      "           1       0.92      1.00      0.96       259\n",
      "\n",
      "    accuracy                           0.97       864\n",
      "   macro avg       0.96      0.98      0.97       864\n",
      "weighted avg       0.97      0.97      0.97       864\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 97.34%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       594\n",
      "           1       0.92      1.00      0.96       270\n",
      "\n",
      "    accuracy                           0.97       864\n",
      "   macro avg       0.96      0.98      0.97       864\n",
      "weighted avg       0.98      0.97      0.97       864\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.982639  0.998682             0.950355          0.996283   \n",
      "1      2  0.972222  0.997096             0.915194          1.000000   \n",
      "2      3  0.973380  0.998472             0.921502          1.000000   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.972777  \n",
      "1            0.955720  \n",
      "2            0.959147  \n",
      "\n",
      "Average Accuracy across trials: 97.61%\n",
      "Average ROC-AUC across trials: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)\n",
    "y = Car[\"car_acceptability\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 95.44%\n",
      "ROC-AUC Score: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       956\n",
      "           1       0.89      0.97      0.93       426\n",
      "\n",
      "    accuracy                           0.95      1382\n",
      "   macro avg       0.94      0.96      0.95      1382\n",
      "weighted avg       0.96      0.95      0.95      1382\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 95.51%\n",
      "ROC-AUC Score: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       975\n",
      "           1       0.88      0.98      0.93       407\n",
      "\n",
      "    accuracy                           0.96      1382\n",
      "   macro avg       0.94      0.96      0.95      1382\n",
      "weighted avg       0.96      0.96      0.96      1382\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 95.88%\n",
      "ROC-AUC Score: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       963\n",
      "           1       0.93      0.94      0.93       419\n",
      "\n",
      "    accuracy                           0.96      1382\n",
      "   macro avg       0.95      0.95      0.95      1382\n",
      "weighted avg       0.96      0.96      0.96      1382\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.954414  0.993554             0.890323          0.971831   \n",
      "1      2  0.955137  0.994830             0.880795          0.980344   \n",
      "2      3  0.958755  0.991940             0.926887          0.937947   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.929293  \n",
      "1            0.927907  \n",
      "2            0.932384  \n",
      "\n",
      "Average Accuracy across trials: 95.61%\n",
      "Average ROC-AUC across trials: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Car.drop(\"car_acceptability\", axis=1)\n",
    "y = Car[\"car_acceptability\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
