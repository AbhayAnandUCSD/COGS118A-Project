{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COGS 118 Project - Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_Marketing = pd.read_csv('bank-full.csv', sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       58    management   married   tertiary      no     2143     yes   no   \n",
       "1       44    technician    single  secondary      no       29     yes   no   \n",
       "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
       "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
       "4       33       unknown    single    unknown      no        1      no   no   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "45206   51    technician   married   tertiary      no      825      no   no   \n",
       "45207   71       retired  divorced    primary      no     1729      no   no   \n",
       "45208   72       retired   married  secondary      no     5715      no   no   \n",
       "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
       "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
       "0        unknown    5   may       261         1     -1         0  unknown   no  \n",
       "1        unknown    5   may       151         1     -1         0  unknown   no  \n",
       "2        unknown    5   may        76         1     -1         0  unknown   no  \n",
       "3        unknown    5   may        92         1     -1         0  unknown   no  \n",
       "4        unknown    5   may       198         1     -1         0  unknown   no  \n",
       "...          ...  ...   ...       ...       ...    ...       ...      ...  ...  \n",
       "45206   cellular   17   nov       977         3     -1         0  unknown  yes  \n",
       "45207   cellular   17   nov       456         2     -1         0  unknown  yes  \n",
       "45208   cellular   17   nov      1127         5    184         3  success  yes  \n",
       "45209  telephone   17   nov       508         4     -1         0  unknown   no  \n",
       "45210   cellular   17   nov       361         2    188        11    other   no  \n",
       "\n",
       "[45211 rows x 17 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check Null Values\n",
    "print(Bank_Marketing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "y            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(Bank_Marketing.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert our Output Variable to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target variable to binary\n",
    "Bank_Marketing['y'] = Bank_Marketing['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "45206    1\n",
       "45207    1\n",
       "45208    1\n",
       "45209    0\n",
       "45210    0\n",
       "Name: y, Length: 45211, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_Marketing['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Relavant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_Marketing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age','housing','education','balance','loan','duration','y']\n",
    "Bank = Bank_Marketing[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_26492\\857297022.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Bank['housing'] = Bank['housing'].map({'yes': 1, 'no': 0, 'unknown': np.nan})\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_26492\\857297022.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Bank['loan'] = Bank['loan'].map({'yes': 1, 'no': 0, 'unknown': np.nan})\n"
     ]
    }
   ],
   "source": [
    "Bank['housing'] = Bank['housing'].map({'yes': 1, 'no': 0, 'unknown': np.nan})\n",
    "Bank['loan'] = Bank['loan'].map({'yes': 1, 'no': 0, 'unknown': np.nan})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_26492\\3473252602.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  Bank = Bank.replace('tertiary',1)\n"
     ]
    }
   ],
   "source": [
    "Bank = Bank.replace('unknown',np.nan)\n",
    "Bank = Bank.replace('primary',0)\n",
    "Bank = Bank.replace('secondary',0.5)\n",
    "Bank = Bank.replace('tertiary',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns to scale\n",
    "columns_to_scale = ['age', 'balance', 'duration']\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale selected columns\n",
    "Bank[columns_to_scale] = scaler.fit_transform(Bank[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.606965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.256419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.437895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.747384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.446762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.707361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.645231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.747384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.447091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>0.947747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.176460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.791329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>2.831227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>2.925401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.429593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.373797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>1.512791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.228024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>-0.370689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.528364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  housing  education   balance  loan  duration  y\n",
       "0      1.606965      1.0        1.0  0.256419   0.0  0.011016  0\n",
       "1      0.288529      1.0        0.5 -0.437895   0.0 -0.416127  0\n",
       "2     -0.747384      1.0        0.5 -0.446762   1.0 -0.707361  0\n",
       "3      0.571051      1.0        NaN  0.047205   0.0 -0.645231  0\n",
       "4     -0.747384      0.0        NaN -0.447091   0.0 -0.233620  0\n",
       "...         ...      ...        ...       ...   ...       ... ..\n",
       "45206  0.947747      0.0        1.0 -0.176460   0.0  2.791329  1\n",
       "45207  2.831227      0.0        0.0  0.120447   0.0  0.768224  1\n",
       "45208  2.925401      0.0        0.5  1.429593   0.0  3.373797  1\n",
       "45209  1.512791      0.0        0.5 -0.228024   0.0  0.970146  0\n",
       "45210 -0.370689      0.0        0.5  0.528364   0.0  0.399328  0\n",
       "\n",
       "[45211 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45211 43354\n"
     ]
    }
   ],
   "source": [
    "rows_b = Bank.shape[0]\n",
    "Bank = Bank.dropna()\n",
    "rows_a = Bank.shape[0]\n",
    "print(rows_b,rows_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    38317\n",
       "1     5037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank.value_counts('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'n_estimators': 500, 'max_features': 'log2', 'criterion': 'entropy'}\n",
      "Test Set Accuracy: 83.72%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90      7638\n",
      "           1       0.38      0.58      0.46      1033\n",
      "\n",
      "    accuracy                           0.84      8671\n",
      "   macro avg       0.66      0.72      0.68      8671\n",
      "weighted avg       0.87      0.84      0.85      8671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Replace with your dataset\n",
    "y = Bank[\"y\"]               # Replace with your dataset\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of combinations to try\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test set using the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.80%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91      7692\n",
      "           1       0.36      0.58      0.44       979\n",
      "\n",
      "    accuracy                           0.84      8671\n",
      "   macro avg       0.65      0.72      0.68      8671\n",
      "weighted avg       0.88      0.84      0.85      8671\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.65%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90      7651\n",
      "           1       0.37      0.57      0.45      1020\n",
      "\n",
      "    accuracy                           0.84      8671\n",
      "   macro avg       0.66      0.72      0.68      8671\n",
      "weighted avg       0.87      0.84      0.85      8671\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.14%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      7629\n",
      "           1       0.38      0.61      0.46      1042\n",
      "\n",
      "    accuracy                           0.83      8671\n",
      "   macro avg       0.66      0.73      0.68      8671\n",
      "weighted avg       0.87      0.83      0.85      8671\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.837966             0.362758          0.575077            0.444883\n",
      "1      2  0.836466             0.372436          0.569608            0.450388\n",
      "2      3  0.831392             0.375445          0.607486            0.464076\n",
      "Average Accuracy across the 3 trials: 83.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90     19122\n",
      "           1       0.37      0.58      0.45      2555\n",
      "\n",
      "    accuracy                           0.84     21677\n",
      "   macro avg       0.66      0.72      0.68     21677\n",
      "weighted avg       0.87      0.84      0.85     21677\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90     19171\n",
      "           1       0.36      0.58      0.45      2506\n",
      "\n",
      "    accuracy                           0.83     21677\n",
      "   macro avg       0.65      0.72      0.67     21677\n",
      "weighted avg       0.87      0.83      0.85     21677\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.98%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     19125\n",
      "           1       0.36      0.58      0.45      2552\n",
      "\n",
      "    accuracy                           0.83     21677\n",
      "   macro avg       0.65      0.72      0.67     21677\n",
      "weighted avg       0.87      0.83      0.85     21677\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.836001             0.373225          0.576125            0.452993\n",
      "1      2  0.832910             0.361401          0.580607            0.445499\n",
      "2      3  0.829820             0.361847          0.583464            0.446678\n",
      "Average Accuracy across the 3 trials: 83.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.36%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90     30662\n",
      "           1       0.36      0.58      0.45      4022\n",
      "\n",
      "    accuracy                           0.83     34684\n",
      "   macro avg       0.65      0.72      0.67     34684\n",
      "weighted avg       0.87      0.83      0.85     34684\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.93%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     30608\n",
      "           1       0.36      0.57      0.44      4076\n",
      "\n",
      "    accuracy                           0.83     34684\n",
      "   macro avg       0.65      0.72      0.67     34684\n",
      "weighted avg       0.87      0.83      0.85     34684\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.07%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90     30631\n",
      "           1       0.36      0.57      0.44      4053\n",
      "\n",
      "    accuracy                           0.83     34684\n",
      "   macro avg       0.65      0.72      0.67     34684\n",
      "weighted avg       0.87      0.83      0.85     34684\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.833641             0.363009          0.575833            0.445299\n",
      "1      2  0.829316             0.358415          0.572620            0.440876\n",
      "2      3  0.830671             0.357946          0.565754            0.438474\n",
      "Average Accuracy across the 3 trials: 83.12%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'entropy', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'C': 1}\n",
      "Accuracy: 79.07%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      7638\n",
      "           1       0.34      0.80      0.48      1033\n",
      "\n",
      "    accuracy                           0.79      8671\n",
      "   macro avg       0.65      0.80      0.67      8671\n",
      "weighted avg       0.89      0.79      0.82      8671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  # Regularization parameter\n",
    "}\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 78.84%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87      7692\n",
      "           1       0.31      0.73      0.44       979\n",
      "\n",
      "    accuracy                           0.79      8671\n",
      "   macro avg       0.64      0.76      0.65      8671\n",
      "weighted avg       0.89      0.79      0.82      8671\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 79.62%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87      7651\n",
      "           1       0.33      0.73      0.46      1020\n",
      "\n",
      "    accuracy                           0.80      8671\n",
      "   macro avg       0.65      0.77      0.67      8671\n",
      "weighted avg       0.88      0.80      0.83      8671\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 78.50%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87      7629\n",
      "           1       0.33      0.74      0.45      1042\n",
      "\n",
      "    accuracy                           0.79      8671\n",
      "   macro avg       0.64      0.77      0.66      8671\n",
      "weighted avg       0.88      0.79      0.82      8671\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.788375             0.312609          0.729316            0.437634\n",
      "1      2  0.796217             0.333333          0.732353            0.458142\n",
      "2      3  0.785031             0.326874          0.744722            0.454333\n",
      "Average Accuracy across the 3 trials: 78.99%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 78.92%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87     19122\n",
      "           1       0.33      0.75      0.46      2555\n",
      "\n",
      "    accuracy                           0.79     21677\n",
      "   macro avg       0.64      0.77      0.66     21677\n",
      "weighted avg       0.88      0.79      0.82     21677\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 79.21%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     19171\n",
      "           1       0.32      0.73      0.45      2506\n",
      "\n",
      "    accuracy                           0.79     21677\n",
      "   macro avg       0.64      0.76      0.66     21677\n",
      "weighted avg       0.88      0.79      0.82     21677\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 78.95%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     19125\n",
      "           1       0.33      0.74      0.45      2552\n",
      "\n",
      "    accuracy                           0.79     21677\n",
      "   macro avg       0.64      0.77      0.66     21677\n",
      "weighted avg       0.88      0.79      0.82     21677\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.789224             0.327450          0.747945            0.455488\n",
      "1      2  0.792084             0.322889          0.727853            0.447333\n",
      "2      3  0.789547             0.325763          0.736285            0.451683\n",
      "Average Accuracy across the 3 trials: 79.03%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 79.22%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     30662\n",
      "           1       0.33      0.74      0.45      4022\n",
      "\n",
      "    accuracy                           0.79     34684\n",
      "   macro avg       0.64      0.77      0.66     34684\n",
      "weighted avg       0.89      0.79      0.82     34684\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 79.11%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     30608\n",
      "           1       0.33      0.75      0.46      4076\n",
      "\n",
      "    accuracy                           0.79     34684\n",
      "   macro avg       0.64      0.77      0.66     34684\n",
      "weighted avg       0.89      0.79      0.82     34684\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 79.43%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     30631\n",
      "           1       0.33      0.73      0.45      4053\n",
      "\n",
      "    accuracy                           0.79     34684\n",
      "   macro avg       0.64      0.77      0.66     34684\n",
      "weighted avg       0.88      0.79      0.82     34684\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.792210             0.325937          0.741422            0.452813\n",
      "1      2  0.791085             0.328612          0.745584            0.456169\n",
      "2      3  0.794314             0.328890          0.730570            0.453585\n",
      "Average Accuracy across the 3 trials: 79.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)  # Features\n",
    "y = Bank[\"y\"]               # Target\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced',C =1, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Best Parameters and Results:\n",
      "Params      {'hidden_size_1': 128, 'hidden_size_2': 64, 'l...\n",
      "Accuracy                                             0.888479\n",
      "Name: 26, dtype: object\n",
      "\n",
      "Best Parameters:\n",
      "Hidden Layer 1 Size: 128\n",
      "Hidden Layer 2 Size: 64\n",
      "Learning Rate: 0.1\n",
      "\n",
      "Best Accuracy: 88.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lr\": [0.001, 0.01, 0.1],                # Learning rates to tune\n",
    "    \"hidden_size_1\": [32, 64, 128],          # Hidden layer 1 sizes to tune\n",
    "    \"hidden_size_2\": [16, 32, 64],           # Hidden layer 2 sizes to tune\n",
    "}\n",
    "\n",
    "# Convert the grid to a list of parameter combinations\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# To store results\n",
    "tuning_results = []\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for params in grid:\n",
    "    print(f\"\\nTesting Parameters: {params}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Define model with hyperparameters\n",
    "    class ANN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(ANN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, params[\"hidden_size_1\"])\n",
    "            self.fc2 = nn.Linear(params[\"hidden_size_1\"], params[\"hidden_size_2\"])\n",
    "            self.fc3 = nn.Linear(params[\"hidden_size_2\"], 2)  # 2 output classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 50  # Fixed number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "\n",
    "    # Append results\n",
    "    tuning_results.append({\n",
    "        \"Params\": params,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display the best parameters\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "best_result = results_df.loc[results_df[\"Accuracy\"].idxmax()]\n",
    "print(\"\\nBest Parameters and Results:\")\n",
    "print(best_result)\n",
    "\n",
    "best_params = best_result[\"Params\"]\n",
    "best_accuracy = best_result[\"Accuracy\"]\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"Hidden Layer 1 Size: {best_params['hidden_size_1']}\")\n",
    "print(f\"Hidden Layer 2 Size: {best_params['hidden_size_2']}\")\n",
    "print(f\"Learning Rate: {best_params['lr']}\")\n",
    "print(f\"\\nBest Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.3120\n",
      "Epoch [20/100], Loss: 0.2946\n",
      "Epoch [30/100], Loss: 0.2834\n",
      "Epoch [40/100], Loss: 0.2711\n",
      "Epoch [50/100], Loss: 0.2649\n",
      "Epoch [60/100], Loss: 0.2610\n",
      "Epoch [70/100], Loss: 0.2582\n",
      "Epoch [80/100], Loss: 0.2563\n",
      "Epoch [90/100], Loss: 0.2550\n",
      "Epoch [100/100], Loss: 0.2542\n",
      "Accuracy: 0.8902\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.3112\n",
      "Epoch [20/100], Loss: 0.2989\n",
      "Epoch [30/100], Loss: 0.2831\n",
      "Epoch [40/100], Loss: 0.2700\n",
      "Epoch [50/100], Loss: 0.2627\n",
      "Epoch [60/100], Loss: 0.2590\n",
      "Epoch [70/100], Loss: 0.2566\n",
      "Epoch [80/100], Loss: 0.2553\n",
      "Epoch [90/100], Loss: 0.2545\n",
      "Epoch [100/100], Loss: 0.2538\n",
      "Accuracy: 0.8932\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.3095\n",
      "Epoch [20/100], Loss: 0.2938\n",
      "Epoch [30/100], Loss: 0.2805\n",
      "Epoch [40/100], Loss: 0.2682\n",
      "Epoch [50/100], Loss: 0.2616\n",
      "Epoch [60/100], Loss: 0.2581\n",
      "Epoch [70/100], Loss: 0.2561\n",
      "Epoch [80/100], Loss: 0.2546\n",
      "Epoch [90/100], Loss: 0.2535\n",
      "Epoch [100/100], Loss: 0.2527\n",
      "Accuracy: 0.8854\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.890209\n",
      "1      2  0.893207\n",
      "2      3  0.885365\n",
      "Average Accuracy: 88.96%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.3498\n",
      "Epoch [20/100], Loss: 0.2931\n",
      "Epoch [30/100], Loss: 0.2774\n",
      "Epoch [40/100], Loss: 0.2661\n",
      "Epoch [50/100], Loss: 0.2602\n",
      "Epoch [60/100], Loss: 0.2561\n",
      "Epoch [70/100], Loss: 0.2536\n",
      "Epoch [80/100], Loss: 0.2521\n",
      "Epoch [90/100], Loss: 0.2510\n",
      "Epoch [100/100], Loss: 0.2500\n",
      "Accuracy: 0.8900\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.3192\n",
      "Epoch [20/100], Loss: 0.2892\n",
      "Epoch [30/100], Loss: 0.2752\n",
      "Epoch [40/100], Loss: 0.2656\n",
      "Epoch [50/100], Loss: 0.2598\n",
      "Epoch [60/100], Loss: 0.2567\n",
      "Epoch [70/100], Loss: 0.2550\n",
      "Epoch [80/100], Loss: 0.2538\n",
      "Epoch [90/100], Loss: 0.2527\n",
      "Epoch [100/100], Loss: 0.2518\n",
      "Accuracy: 0.8916\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.3046\n",
      "Epoch [20/100], Loss: 0.2962\n",
      "Epoch [30/100], Loss: 0.2838\n",
      "Epoch [40/100], Loss: 0.2705\n",
      "Epoch [50/100], Loss: 0.2629\n",
      "Epoch [60/100], Loss: 0.2583\n",
      "Epoch [70/100], Loss: 0.2555\n",
      "Epoch [80/100], Loss: 0.2536\n",
      "Epoch [90/100], Loss: 0.2521\n",
      "Epoch [100/100], Loss: 0.2512\n",
      "Accuracy: 0.8892\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.889976\n",
      "1      2  0.891590\n",
      "2      3  0.889237\n",
      "Average Accuracy: 89.03%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.3288\n",
      "Epoch [20/100], Loss: 0.3059\n",
      "Epoch [30/100], Loss: 0.2867\n",
      "Epoch [40/100], Loss: 0.2742\n",
      "Epoch [50/100], Loss: 0.2657\n",
      "Epoch [60/100], Loss: 0.2596\n",
      "Epoch [70/100], Loss: 0.2553\n",
      "Epoch [80/100], Loss: 0.2518\n",
      "Epoch [90/100], Loss: 0.2488\n",
      "Epoch [100/100], Loss: 0.2460\n",
      "Accuracy: 0.8908\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.3144\n",
      "Epoch [20/100], Loss: 0.2809\n",
      "Epoch [30/100], Loss: 0.2671\n",
      "Epoch [40/100], Loss: 0.2588\n",
      "Epoch [50/100], Loss: 0.2532\n",
      "Epoch [60/100], Loss: 0.2493\n",
      "Epoch [70/100], Loss: 0.2461\n",
      "Epoch [80/100], Loss: 0.2438\n",
      "Epoch [90/100], Loss: 0.2416\n",
      "Epoch [100/100], Loss: 0.2393\n",
      "Accuracy: 0.8867\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.3156\n",
      "Epoch [20/100], Loss: 0.2808\n",
      "Epoch [30/100], Loss: 0.2629\n",
      "Epoch [40/100], Loss: 0.2529\n",
      "Epoch [50/100], Loss: 0.2488\n",
      "Epoch [60/100], Loss: 0.2461\n",
      "Epoch [70/100], Loss: 0.2435\n",
      "Epoch [80/100], Loss: 0.2414\n",
      "Epoch [90/100], Loss: 0.2394\n",
      "Epoch [100/100], Loss: 0.2381\n",
      "Accuracy: 0.8880\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.890757\n",
      "1      2  0.886749\n",
      "2      3  0.887960\n",
      "Average Accuracy: 88.85%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam Tuning Using Normal Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_auc = 0\n",
    "\n",
    "for n_estimators in [100, 200, 300]:\n",
    "    for max_depth in [3, 5, 7]:\n",
    "        for learning_rate in [0.01, 0.05, 0.1]:\n",
    "            xgb = XGBClassifier(\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            xgb.fit(X_train, y_train)\n",
    "            y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_depth': max_depth,\n",
    "                    'learning_rate': learning_rate\n",
    "                }\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 80.68%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88      7692\n",
      "           1       0.34      0.76      0.47       979\n",
      "\n",
      "    accuracy                           0.81      8671\n",
      "   macro avg       0.65      0.79      0.68      8671\n",
      "weighted avg       0.89      0.81      0.84      8671\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:58:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:58:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.75%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88      7651\n",
      "           1       0.35      0.77      0.48      1020\n",
      "\n",
      "    accuracy                           0.81      8671\n",
      "   macro avg       0.66      0.79      0.68      8671\n",
      "weighted avg       0.89      0.81      0.83      8671\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 80.05%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88      7629\n",
      "           1       0.35      0.78      0.48      1042\n",
      "\n",
      "    accuracy                           0.80      8671\n",
      "   macro avg       0.66      0.79      0.68      8671\n",
      "weighted avg       0.89      0.80      0.83      8671\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.806827  0.872791             0.340805          0.760981   \n",
      "1      2  0.807519  0.868802             0.353234          0.765686   \n",
      "2      3  0.800484  0.870787             0.351468          0.781190   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.470774  \n",
      "1            0.483442  \n",
      "2            0.484812  \n",
      "\n",
      "Average Accuracy across trials: 80.49%\n",
      "Average ROC-AUC across trials: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:58:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)\n",
    "y = Bank[\"y\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 80.96%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88     19122\n",
      "           1       0.36      0.76      0.49      2555\n",
      "\n",
      "    accuracy                           0.81     21677\n",
      "   macro avg       0.66      0.79      0.68     21677\n",
      "weighted avg       0.89      0.81      0.84     21677\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.12%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88     19171\n",
      "           1       0.34      0.77      0.47      2506\n",
      "\n",
      "    accuracy                           0.80     21677\n",
      "   macro avg       0.65      0.79      0.67     21677\n",
      "weighted avg       0.89      0.80      0.83     21677\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 80.14%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88     19125\n",
      "           1       0.35      0.77      0.48      2552\n",
      "\n",
      "    accuracy                           0.80     21677\n",
      "   macro avg       0.65      0.79      0.68     21677\n",
      "weighted avg       0.89      0.80      0.83     21677\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.809568  0.869648             0.356242          0.762818   \n",
      "1      2  0.801218  0.866845             0.340753          0.769753   \n",
      "2      3  0.801356  0.866682             0.345326          0.767241   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.485672  \n",
      "1            0.472389  \n",
      "2            0.476283  \n",
      "\n",
      "Average Accuracy across trials: 80.40%\n",
      "Average ROC-AUC across trials: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)\n",
    "y = Bank[\"y\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 81.22%\n",
      "ROC-AUC Score: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89     30662\n",
      "           1       0.35      0.75      0.48      4022\n",
      "\n",
      "    accuracy                           0.81     34684\n",
      "   macro avg       0.66      0.78      0.68     34684\n",
      "weighted avg       0.89      0.81      0.84     34684\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.31%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88     30608\n",
      "           1       0.35      0.78      0.48      4076\n",
      "\n",
      "    accuracy                           0.80     34684\n",
      "   macro avg       0.66      0.79      0.68     34684\n",
      "weighted avg       0.89      0.80      0.83     34684\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 81.07%\n",
      "ROC-AUC Score: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88     30631\n",
      "           1       0.35      0.75      0.48      4053\n",
      "\n",
      "    accuracy                           0.81     34684\n",
      "   macro avg       0.66      0.79      0.68     34684\n",
      "weighted avg       0.89      0.81      0.84     34684\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.812190  0.864746             0.353412          0.746892   \n",
      "1      2  0.803079  0.865314             0.348248          0.775270   \n",
      "2      3  0.810662  0.865304             0.354176          0.753269   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.479796  \n",
      "1            0.480608  \n",
      "2            0.481812  \n",
      "\n",
      "Average Accuracy across trials: 80.86%\n",
      "Average ROC-AUC across trials: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:59:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'Bank' is your DataFrame with the target column 'y'\n",
    "# Separate features and target\n",
    "X = Bank.drop(\"y\", axis=1)\n",
    "y = Bank[\"y\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
