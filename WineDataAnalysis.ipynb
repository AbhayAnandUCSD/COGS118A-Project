{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wine_r = pd.read_csv('winequality-red.csv', sep=\";\")\n",
    "Wine_w = pd.read_csv('winequality-white.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wine_r['is_red'] = 1  # 1 indicates red wine\n",
    "Wine_w['is_red'] = 0  # 0 indicates white wine\n",
    "\n",
    "# Concatenate the two datasets\n",
    "wine_combined = pd.concat([Wine_r, Wine_w], axis=0, ignore_index=True)\n",
    "X = wine_combined.drop(\"is_red\", axis=1)  # Features\n",
    "y = wine_combined[\"is_red\"]  # Target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'n_estimators': 500, 'max_features': 'log2', 'criterion': 'gini'}\n",
      "Test Set Accuracy: 99.62%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       959\n",
      "           1       1.00      0.99      0.99       341\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Oversample the minority class using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of combinations to try\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test set using the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.54%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       989\n",
      "           1       0.99      0.99      0.99       311\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.54%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1003\n",
      "           1       0.99      0.99      0.99       297\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.85%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       968\n",
      "           1       1.00      0.99      1.00       332\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.995385             0.987220          0.993569            0.990385\n",
      "1      2  0.995385             0.989899          0.989899            0.989899\n",
      "2      3  0.998462             1.000000          0.993976            0.996979\n",
      "Average Accuracy across the 3 trials: 99.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'gini', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.57%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2440\n",
      "           1       0.99      0.99      0.99       809\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       1.00      0.99      0.99      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2453\n",
      "           1       1.00      0.99      0.99       796\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       1.00      0.99      0.99      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2412\n",
      "           1       1.00      0.99      0.99       837\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       1.00      0.99      0.99      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.995691             0.993789          0.988875            0.991326\n",
      "1      2  0.995999             0.997459          0.986181            0.991788\n",
      "2      3  0.995999             0.997585          0.986858            0.992192\n",
      "Average Accuracy across the 3 trials: 99.59%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'gini', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.40%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3904\n",
      "           1       0.99      0.98      0.99      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.25%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3904\n",
      "           1       1.00      0.97      0.98      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.25%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3912\n",
      "           1       0.99      0.98      0.98      1286\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.994036             0.992206          0.983771            0.987971\n",
      "1      2  0.992497             0.996047          0.973725            0.984760\n",
      "2      3  0.992497             0.989788          0.979782            0.984760\n",
      "Average Accuracy across the 3 trials: 99.30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Train-test split with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Oversample the minority class using SMOTE\n",
    "    smote = SMOTE(random_state=i)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train Random Forest Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_features = 'log2', criterion = 'gini', random_state=i)\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'C': 1000}\n",
      "Accuracy: 98.31%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       959\n",
      "           1       0.96      0.98      0.97       341\n",
      "\n",
      "    accuracy                           0.98      1300\n",
      "   macro avg       0.98      0.98      0.98      1300\n",
      "weighted avg       0.98      0.98      0.98      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  # Regularization parameter\n",
    "}\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 98.92%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       989\n",
      "           1       0.97      0.99      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.98      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 98.31%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1003\n",
      "           1       0.94      0.98      0.96       297\n",
      "\n",
      "    accuracy                           0.98      1300\n",
      "   macro avg       0.97      0.98      0.98      1300\n",
      "weighted avg       0.98      0.98      0.98      1300\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 98.85%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       968\n",
      "           1       0.96      0.99      0.98       332\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.98      0.99      0.98      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.989231             0.965517          0.990354            0.977778\n",
      "1      2  0.983077             0.944984          0.983165            0.963696\n",
      "2      3  0.988462             0.962099          0.993976            0.977778\n",
      "Average Accuracy across the 3 trials: 98.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 98.74%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2440\n",
      "           1       0.97      0.98      0.97       809\n",
      "\n",
      "    accuracy                           0.99      3249\n",
      "   macro avg       0.98      0.99      0.98      3249\n",
      "weighted avg       0.99      0.99      0.99      3249\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 98.31%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      2453\n",
      "           1       0.94      0.99      0.97       796\n",
      "\n",
      "    accuracy                           0.98      3249\n",
      "   macro avg       0.97      0.98      0.98      3249\n",
      "weighted avg       0.98      0.98      0.98      3249\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 98.09%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2412\n",
      "           1       0.94      0.99      0.96       837\n",
      "\n",
      "    accuracy                           0.98      3249\n",
      "   macro avg       0.97      0.98      0.98      3249\n",
      "weighted avg       0.98      0.98      0.98      3249\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.987381             0.966019          0.983931            0.974893\n",
      "1      2  0.983072             0.944778          0.988693            0.966237\n",
      "2      3  0.980917             0.942857          0.985663            0.963785\n",
      "Average Accuracy across the 3 trials: 98.38%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced', C = 1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 98.69%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3904\n",
      "           1       0.97      0.97      0.97      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.98      0.98      0.98      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 98.58%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3904\n",
      "           1       0.96      0.98      0.97      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.98      0.99      0.98      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 97.98%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3912\n",
      "           1       0.94      0.98      0.96      1286\n",
      "\n",
      "    accuracy                           0.98      5198\n",
      "   macro avg       0.97      0.98      0.97      5198\n",
      "weighted avg       0.98      0.98      0.98      5198\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy  Precision (Class 1)  Recall (Class 1)  F1-Score (Class 1)\n",
      "0      1  0.986918             0.972994          0.974498            0.973745\n",
      "1      2  0.985764             0.959337          0.984544            0.971777\n",
      "2      3  0.979800             0.937732          0.983670            0.960152\n",
      "Average Accuracy across the 3 trials: 98.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# To store results for each test\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Perform train-test split with different random seeds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=i)\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    classifier = SVC(kernel='linear', class_weight='balanced',C =1000, random_state=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "    \n",
    "    # Print results for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display overall results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "print(f\"Average Accuracy across the 3 trials: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 32, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 64, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 16, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 32, 'lr': 0.1}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.001}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.01}\n",
      "\n",
      "Testing Parameters: {'hidden_size_1': 128, 'hidden_size_2': 64, 'lr': 0.1}\n",
      "\n",
      "Best Parameters and Results:\n",
      "Params      {'hidden_size_1': 32, 'hidden_size_2': 32, 'lr...\n",
      "Accuracy                                             0.995385\n",
      "Name: 5, dtype: object\n",
      "\n",
      "Best Parameters:\n",
      "Hidden Layer 1 Size: 32\n",
      "Hidden Layer 2 Size: 32\n",
      "Learning Rate: 0.1\n",
      "\n",
      "Best Accuracy: 99.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lr\": [0.001, 0.01, 0.1],                # Learning rates to tune\n",
    "    \"hidden_size_1\": [32, 64, 128],          # Hidden layer 1 sizes to tune\n",
    "    \"hidden_size_2\": [16, 32, 64],           # Hidden layer 2 sizes to tune\n",
    "}\n",
    "\n",
    "# Convert the grid to a list of parameter combinations\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# To store results\n",
    "tuning_results = []\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for params in grid:\n",
    "    print(f\"\\nTesting Parameters: {params}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Define model with hyperparameters\n",
    "    class ANN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(ANN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, params[\"hidden_size_1\"])\n",
    "            self.fc2 = nn.Linear(params[\"hidden_size_1\"], params[\"hidden_size_2\"])\n",
    "            self.fc3 = nn.Linear(params[\"hidden_size_2\"], 2)  # 2 output classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 50  # Fixed number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "\n",
    "    # Append results\n",
    "    tuning_results.append({\n",
    "        \"Params\": params,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display the best parameters\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "best_result = results_df.loc[results_df[\"Accuracy\"].idxmax()]\n",
    "print(\"\\nBest Parameters and Results:\")\n",
    "print(best_result)\n",
    "\n",
    "best_params = best_result[\"Params\"]\n",
    "best_accuracy = best_result[\"Accuracy\"]\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"Hidden Layer 1 Size: {best_params['hidden_size_1']}\")\n",
    "print(f\"Hidden Layer 2 Size: {best_params['hidden_size_2']}\")\n",
    "print(f\"Learning Rate: {best_params['lr']}\")\n",
    "print(f\"\\nBest Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.0377\n",
      "Epoch [20/100], Loss: 0.0457\n",
      "Epoch [30/100], Loss: 0.0174\n",
      "Epoch [40/100], Loss: 0.0127\n",
      "Epoch [50/100], Loss: 0.0103\n",
      "Epoch [60/100], Loss: 0.0081\n",
      "Epoch [70/100], Loss: 0.0061\n",
      "Epoch [80/100], Loss: 0.0035\n",
      "Epoch [90/100], Loss: 0.0017\n",
      "Epoch [100/100], Loss: 0.0006\n",
      "Accuracy: 0.9938\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.0585\n",
      "Epoch [20/100], Loss: 0.0498\n",
      "Epoch [30/100], Loss: 0.0206\n",
      "Epoch [40/100], Loss: 0.0161\n",
      "Epoch [50/100], Loss: 0.0123\n",
      "Epoch [60/100], Loss: 0.0103\n",
      "Epoch [70/100], Loss: 0.0090\n",
      "Epoch [80/100], Loss: 0.0080\n",
      "Epoch [90/100], Loss: 0.0070\n",
      "Epoch [100/100], Loss: 0.0061\n",
      "Accuracy: 0.9954\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.0355\n",
      "Epoch [20/100], Loss: 0.0865\n",
      "Epoch [30/100], Loss: 0.0656\n",
      "Epoch [40/100], Loss: 0.0213\n",
      "Epoch [50/100], Loss: 0.0128\n",
      "Epoch [60/100], Loss: 0.0095\n",
      "Epoch [70/100], Loss: 0.0073\n",
      "Epoch [80/100], Loss: 0.0060\n",
      "Epoch [90/100], Loss: 0.0050\n",
      "Epoch [100/100], Loss: 0.0041\n",
      "Accuracy: 0.9931\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.993846\n",
      "1      2  0.995385\n",
      "2      3  0.993077\n",
      "Average Accuracy: 99.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.0516\n",
      "Epoch [20/100], Loss: 0.0762\n",
      "Epoch [30/100], Loss: 0.0518\n",
      "Epoch [40/100], Loss: 0.0203\n",
      "Epoch [50/100], Loss: 0.0133\n",
      "Epoch [60/100], Loss: 0.0107\n",
      "Epoch [70/100], Loss: 0.0088\n",
      "Epoch [80/100], Loss: 0.0077\n",
      "Epoch [90/100], Loss: 0.0071\n",
      "Epoch [100/100], Loss: 0.0064\n",
      "Accuracy: 0.9954\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.0587\n",
      "Epoch [20/100], Loss: 0.0214\n",
      "Epoch [30/100], Loss: 0.0122\n",
      "Epoch [40/100], Loss: 0.0065\n",
      "Epoch [50/100], Loss: 0.0033\n",
      "Epoch [60/100], Loss: 0.0017\n",
      "Epoch [70/100], Loss: 0.0007\n",
      "Epoch [80/100], Loss: 0.0002\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0001\n",
      "Accuracy: 0.9960\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.0896\n",
      "Epoch [20/100], Loss: 0.0590\n",
      "Epoch [30/100], Loss: 0.0162\n",
      "Epoch [40/100], Loss: 0.0065\n",
      "Epoch [50/100], Loss: 0.0039\n",
      "Epoch [60/100], Loss: 0.0027\n",
      "Epoch [70/100], Loss: 0.0019\n",
      "Epoch [80/100], Loss: 0.0015\n",
      "Epoch [90/100], Loss: 0.0012\n",
      "Epoch [100/100], Loss: 0.0011\n",
      "Accuracy: 0.9960\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.995383\n",
      "1      2  0.995999\n",
      "2      3  0.995999\n",
      "Average Accuracy: 99.58%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Epoch [10/100], Loss: 0.0901\n",
      "Epoch [20/100], Loss: 0.0393\n",
      "Epoch [30/100], Loss: 0.0077\n",
      "Epoch [40/100], Loss: 0.0030\n",
      "Epoch [50/100], Loss: 0.0009\n",
      "Epoch [60/100], Loss: 0.0003\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [80/100], Loss: 0.0001\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Accuracy: 0.9906\n",
      "\n",
      "--- Trial 2 ---\n",
      "Epoch [10/100], Loss: 0.0363\n",
      "Epoch [20/100], Loss: 0.0195\n",
      "Epoch [30/100], Loss: 0.0099\n",
      "Epoch [40/100], Loss: 0.0068\n",
      "Epoch [50/100], Loss: 0.0037\n",
      "Epoch [60/100], Loss: 0.0011\n",
      "Epoch [70/100], Loss: 0.0003\n",
      "Epoch [80/100], Loss: 0.0001\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0001\n",
      "Accuracy: 0.9896\n",
      "\n",
      "--- Trial 3 ---\n",
      "Epoch [10/100], Loss: 0.0321\n",
      "Epoch [20/100], Loss: 0.0046\n",
      "Epoch [30/100], Loss: 0.0007\n",
      "Epoch [40/100], Loss: 0.0001\n",
      "Epoch [50/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Accuracy: 0.9933\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy\n",
      "0      1  0.990573\n",
      "1      2  0.989611\n",
      "2      3  0.993267\n",
      "Average Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 random tests\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "    \n",
    "    # Split data with a different random seed\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANN(input_size=X_train.shape[1])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).argmax(dim=1)\n",
    "        accuracy = (y_pred == y_test).float().mean().item()\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Append results\n",
    "    results.append({\"Trial\": i + 1, \"Accuracy\": accuracy})\n",
    "\n",
    "# Summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "print(f\"Average Accuracy: {results_df['Accuracy'].mean() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam Tuning Using Normal Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_auc = 0\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "for n_estimators in [100, 200, 300]:\n",
    "    for max_depth in [3, 5, 7]:\n",
    "        for learning_rate in [0.01, 0.05, 0.1]:\n",
    "            xgb = XGBClassifier(\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            xgb.fit(X_train, y_train)\n",
    "            y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_depth': max_depth,\n",
    "                    'learning_rate': learning_rate\n",
    "                }\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 99.23%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       989\n",
      "           1       0.97      0.99      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:00:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:00:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.46%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1003\n",
      "           1       0.99      0.99      0.99       297\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 99.77%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       968\n",
      "           1       0.99      1.00      1.00       332\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.992308  0.999854             0.974763          0.993569   \n",
      "1      2  0.994615  0.996727             0.989865          0.986532   \n",
      "2      3  0.997692  0.999788             0.993994          0.996988   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.984076  \n",
      "1            0.988196  \n",
      "2            0.995489  \n",
      "\n",
      "Average Accuracy across trials: 99.49%\n",
      "Average ROC-AUC across trials: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:00:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 99.63%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2440\n",
      "           1       0.99      0.99      0.99       809\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       1.00      1.00      1.00      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.57%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2453\n",
      "           1       0.99      0.99      0.99       796\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       1.00      0.99      0.99      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n",
      "Accuracy: 99.54%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2412\n",
      "           1       0.99      0.99      0.99       837\n",
      "\n",
      "    accuracy                           1.00      3249\n",
      "   macro avg       0.99      0.99      0.99      3249\n",
      "weighted avg       1.00      1.00      1.00      3249\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.996307  0.999679             0.992583          0.992583   \n",
      "1      2  0.995691  0.998149             0.993687          0.988693   \n",
      "2      3  0.995383  0.997268             0.993990          0.988053   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.992583  \n",
      "1            0.991184  \n",
      "2            0.991013  \n",
      "\n",
      "Average Accuracy across trials: 99.58%\n",
      "Average ROC-AUC across trials: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.5, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Trial 1 ---\n",
      "Accuracy: 99.27%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3904\n",
      "           1       0.99      0.99      0.99      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 2 ---\n",
      "Accuracy: 99.06%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3904\n",
      "           1       0.98      0.98      0.98      1294\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "--- Trial 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.19%\n",
      "ROC-AUC Score: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3912\n",
      "           1       0.99      0.98      0.98      1286\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.99      0.99      5198\n",
      "weighted avg       0.99      0.99      0.99      5198\n",
      "\n",
      "\n",
      "Summary of Results Across Trials:\n",
      "   Trial  Accuracy   ROC-AUC  Precision (Class 1)  Recall (Class 1)  \\\n",
      "0      1  0.992689  0.997363             0.985317          0.985317   \n",
      "1      2  0.990573  0.998557             0.983683          0.978362   \n",
      "2      3  0.991920  0.996204             0.988994          0.978227   \n",
      "\n",
      "   F1-Score (Class 1)  \n",
      "0            0.985317  \n",
      "1            0.981015  \n",
      "2            0.983581  \n",
      "\n",
      "Average Accuracy across trials: 99.17%\n",
      "Average ROC-AUC across trials: 1.00\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Perform 3 trials\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Trial {i + 1} ---\")\n",
    "\n",
    "    # Split the data with a different random seed each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.8, random_state=i\n",
    "    )\n",
    "\n",
    "    # Calculate scale_pos_weight to handle class imbalance\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 0.8\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=i,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Trial\": i + 1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"F1-Score (Class 1)\": report[\"1\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Print metrics for this trial\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results Across Trials:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print the average metrics across trials\n",
    "average_accuracy = results_df[\"Accuracy\"].mean()\n",
    "average_roc_auc = results_df[\"ROC-AUC\"].mean()\n",
    "print(f\"\\nAverage Accuracy across trials: {average_accuracy * 100:.2f}%\")\n",
    "print(f\"Average ROC-AUC across trials: {average_roc_auc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
